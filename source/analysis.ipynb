{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports and data\n",
   "id": "ce6a5cafb5ab3e71"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load CSV again, skipping the second header row\n",
    "df = pd.read_csv(\"../data/results_all_cleaned.csv\", skiprows=[1])\n",
    "\n",
    "# Split dataset into groups\n",
    "df_prolific = df[df[\"Q0_ProlificID\"].notna()]\n",
    "df_infodienst = df[df[\"Q0_ProlificID\"].isna()]\n"
   ],
   "id": "4c6e32b55b339e8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Add the second conversation description to the same column\n",
    "row0 = df.iloc[0]\n",
    "same_as_header = (row0.values == df.columns.values[:len(row0)]).sum()\n",
    "if same_as_header >= len(df.columns) * 0.3:\n",
    "    df = df.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "meta = df.iloc[:, 0:9]\n",
    "block_a = df.iloc[:, 9:33]\n",
    "block_b = df.iloc[:, 33:57]\n",
    "keep_tail = df.iloc[:, 57:63]\n",
    "\n",
    "block_b.columns = block_a.columns\n",
    "\n",
    "df_a = pd.concat([meta.copy(), block_a.copy(), keep_tail.copy()], axis=1)\n",
    "df_b = pd.concat([meta.copy(), block_b.copy(), keep_tail.copy()], axis=1)\n",
    "df_with_second_conv = pd.concat([df_a, df_b], axis=0, ignore_index=True)\n",
    "\n",
    "df_with_second_conv\n"
   ],
   "id": "2f1125beb9ed9e1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Analysis of questions",
   "id": "2d86a21e1bfa9f2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Q3: How many people were involved, apart from you?",
   "id": "8c903525a4d8d3ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def preprocess_participants(df_input, column):\n",
    "    df_input = df_input.copy()\n",
    "\n",
    "    df_exploded = df_input.dropna().astype(int).explode(column)\n",
    "\n",
    "    return df_exploded.reset_index()[[column]]\n",
    "\n",
    "def plot_participants(df_input, column, title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Replace all values >10 with 10 (will represent \"10+\")\n",
    "    data = df_input[column].clip(upper=10)\n",
    "\n",
    "    # Count occurrences for 1–9 and the binned \"10+\"\n",
    "    counts = data.value_counts().reindex(range(1, 11), fill_value=0)\n",
    "\n",
    "    # Plot bars\n",
    "    bars = plt.bar(counts.index, counts.values, width=0.9, edgecolor=\"none\")\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "    plt.title(\"Number of conversation partners\")\n",
    "    plt.xlabel(\"Number of conversation partners\")\n",
    "    plt.ylabel(\"Number of participants\", color=\"gray\")\n",
    "    plt.grid(axis=\"x\")\n",
    "\n",
    "    labels = list(range(1, 10)) + [\"10 or more\"]\n",
    "    plt.xticks(range(1, 11), labels)\n",
    "\n",
    "    plt.xlim(0.5, 10.5)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "df_preprocessed = preprocess_participants(df_with_second_conv[[\"Q3\"]], \"Q3\")\n",
    "\n",
    "plot_participants(df_preprocessed, \"Q3\", 'Number of conversation partners')\n",
    "\n",
    "vals = pd.to_numeric(df_preprocessed[\"Q3\"], errors=\"coerce\")\n",
    "binned = vals.where(vals <= 4, 4)\n",
    "counts = binned.value_counts().reindex([1, 2, 3, 4], fill_value=0).sort_index()\n",
    "shares_pct = (counts / counts.sum() * 100).round()\n",
    "\n",
    "result = pd.DataFrame(\n",
    "    {\"count\": counts.values, \"share_%\": shares_pct.values},\n",
    "    index=[\"1\", \"2\", \"3\", \"4+\"]\n",
    ")\n",
    "\n",
    "print(result)\n"
   ],
   "id": "ee607708fb7dd478",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Q5: Who started the conversation?",
   "id": "260488749e93a3b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def preprocess_initiator(df_input, column):\n",
    "    df_input = df_input.copy()\n",
    "\n",
    "    df_exploded = df_input.dropna(subset=[column]).explode(column)\n",
    "\n",
    "    return df_exploded.reset_index()[[column]]\n",
    "\n",
    "def plot_initiator(df_input, column, title):\n",
    "    counts = df_input[column].value_counts()\n",
    "\n",
    "    counts = counts.sort_values(ascending=True)\n",
    "\n",
    "    colors = plt.cm.tab20.colors\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "    wedges, texts, autotexts = ax.pie(counts, labels=counts.index, autopct='%1.f%%', startangle=90, colors=colors)\n",
    "\n",
    "    # Add absolute values to the pie chart\n",
    "    for autotext, label in zip(autotexts, counts.index):\n",
    "        percentage_text = autotext.get_text()\n",
    "        count = counts[label]\n",
    "        autotext.set_text(f'{percentage_text}\\n({count})')\n",
    "\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.axis('equal')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "df_preprocessed = preprocess_initiator(df_with_second_conv[[\"Q5\"]], \"Q5\")\n",
    "\n",
    "plot_initiator(df_preprocessed, \"Q5\", 'Conversation initiator')\n"
   ],
   "id": "5cb7ad3b00b516f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Q6: Did anybody else join the conversation after you started?",
   "id": "f3f01c0997e1bbe3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def preprocess_initiator(df_input, column):\n",
    "    df_input = df_input.copy()\n",
    "\n",
    "    df_exploded = df_input.dropna(subset=[column]).explode(column)\n",
    "\n",
    "    return df_exploded.reset_index()[[column]]\n",
    "\n",
    "def plot_initiator(df_input, column, title):\n",
    "    counts = df_input[column].value_counts()\n",
    "\n",
    "    counts = counts.sort_values(ascending=True)\n",
    "\n",
    "    colors = plt.cm.tab20.colors\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "    wedges, texts, autotexts = ax.pie(counts, labels=counts.index, autopct='%1.f%%', colors=colors)\n",
    "\n",
    "    # Add absolute values to the pie chart\n",
    "    for autotext, label in zip(autotexts, counts.index):\n",
    "        percentage_text = autotext.get_text()\n",
    "        count = counts[label]\n",
    "        autotext.set_text(f'{percentage_text}\\n({count})')\n",
    "\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "df_preprocessed = preprocess_initiator(df_with_second_conv[[\"Q6\"]], \"Q6\")\n",
    "\n",
    "plot_initiator(df_preprocessed, \"Q6\", 'Did anybody join the conversation after it started')\n"
   ],
   "id": "b9790c0a9a26b2cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Q7: Where did this conversation happen?",
   "id": "de52ed5828479dab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def preprocess_setting(df_input, column, second_column):\n",
    "    df_input = df_input.copy()\n",
    "\n",
    "    df_input[column] = df_input.apply(\n",
    "        lambda row: row[second_column]\n",
    "        if str(row[column]).strip() == \"Other (please specify)\" and pd.notna(row[second_column])\n",
    "        else row[column],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    df_exploded = df_input.dropna(subset=[column]).assign(\n",
    "        conv=df_input[column].dropna().str.strip()\n",
    "    ).explode(column)\n",
    "\n",
    "    df_exploded[column] = df_exploded[column].replace(\n",
    "        {\"Public space (e.g., café, train)\": \"Public space\"}\n",
    "    )\n",
    "\n",
    "    df_exploded = df_exploded[df_exploded[column] != \"Other (please specify)\"]\n",
    "\n",
    "    to_other = {\"party\", \"online\", \"Online call\", \"phone call\", \"chat\", \"doctor's office\", \"car\", \"Online call\"}\n",
    "    df_exploded[column] = df_exploded[column].apply(\n",
    "        lambda x: \"Other\" if x.strip().lower() in to_other else x\n",
    "    )\n",
    "\n",
    "    return df_exploded.reset_index()[[column]]\n",
    "\n",
    "def plot_setting(df_exploded, column, title):\n",
    "    counts_final = df_exploded[column].value_counts()\n",
    "    counts_final = counts_final.sort_values(ascending=True)\n",
    "    total_responses = counts_final.sum()\n",
    "    q7_percentages = (counts_final / total_responses) * 100\n",
    "    print(q7_percentages)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    bars = counts_final.plot(kind=\"barh\", ax=ax)\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.set_xlabel(\"Number of participants\", alpha=0.6)\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.tick_params(axis='y', rotation=0)\n",
    "    plt.grid(axis='x', alpha=0.6)\n",
    "    ax.grid(axis='y', visible=False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "    for i in range(len(counts_final)):\n",
    "        count = counts_final.iloc[i]\n",
    "        percentage = q7_percentages.iloc[i]\n",
    "        ax.text(count + 1, i, f'{percentage:.0f} %\\n({count})', ha='left', va='center', alpha=0.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "df_preprocessed = preprocess_setting(df_with_second_conv[[\"Q7\", \"Q7_4_TEXT\"]], \"Q7\", \"Q7_4_TEXT\")\n",
    "\n",
    "plot_setting(df_preprocessed, \"Q7\", 'Setting of the cybersecurity conversation')\n"
   ],
   "id": "72ca28f88abf7e36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Q8: What led to the topic of cybersecurity coming up?",
   "id": "cf9410bb6d06b4c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def preprocess_trigger(df_input, column):\n",
    "    df_input = df_input.copy()\n",
    "\n",
    "    df_input = df_input.loc[df_input[column].notna()].copy()\n",
    "\n",
    "    df_input[column] = (\n",
    "        df_input[column].astype(str)\n",
    "        .str.split(\",\")\n",
    "    )\n",
    "\n",
    "    n_respondents = df_input.shape[0]\n",
    "\n",
    "    df_exploded = df_input.explode(column)\n",
    "    df_exploded[column] = df_exploded[column].str.strip()\n",
    "\n",
    "    df_exploded[column] = df_exploded[column].replace({\n",
    "        \"Other (please specify)\": \"Other\",\n",
    "        \"Personal experience (e.g. cybersecurity incident)\": \"Personal experience\"\n",
    "    })\n",
    "\n",
    "    return df_exploded.reset_index()[[column]], n_respondents\n",
    "\n",
    "def plot_trigger(df_input, n_respondents, column, title):\n",
    "    counts = df_input[column].value_counts().sort_values(ascending=True)\n",
    "\n",
    "    percent = (counts / n_respondents) * 100\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    counts.plot(kind=\"barh\", ax=ax)\n",
    "\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.set_xlabel(\"Participants selecting option\", alpha=0.6)\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.tick_params(axis='y', rotation=0)\n",
    "    ax.grid(axis='x', alpha=0.6)\n",
    "    ax.grid(axis='y', visible=False)\n",
    "    for spine in ['top','right','bottom']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "\n",
    "    for i, (cat, count) in enumerate(counts.items()):\n",
    "        pct = percent.loc[cat]\n",
    "        ax.text(count + max(counts)*0.01, i, f\"{pct:.0f}%\\n({count})\",\n",
    "                ha=\"left\", va=\"center\", alpha=0.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "df_preprocessed, n_respondents = preprocess_trigger(df_with_second_conv[[\"Q8\"]], \"Q8\")\n",
    "\n",
    "plot_trigger(df_preprocessed, n_respondents, \"Q8\", \"Conversation trigger\")\n"
   ],
   "id": "de9a284396269b3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Q9: What specific cybersecurity issue(s) did you discuss?",
   "id": "28d101567237fe2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def preprocess_topics(df_input, column):\n",
    "    df_input = df_input.copy()\n",
    "\n",
    "    df_input = df_input.loc[df_input[column].notna()].copy()\n",
    "\n",
    "    df_input[column] = (\n",
    "        df_input[column].astype(str)\n",
    "        .str.split(\",\")\n",
    "    )\n",
    "\n",
    "    n_respondents = df_input.shape[0]\n",
    "\n",
    "    df_exploded = df_input.explode(column)\n",
    "    df_exploded[column] = df_exploded[column].str.strip()\n",
    "\n",
    "    df_exploded[column] = df_exploded[column].replace({\n",
    "        \"Other (please specify)\": \"Other\"\n",
    "    })\n",
    "\n",
    "    return df_exploded.reset_index()[[column]], n_respondents\n",
    "\n",
    "def plot_topics(df_input, n_respondents, column, title):\n",
    "    counts = df_input[column].value_counts().sort_values(ascending=True)\n",
    "\n",
    "    percent = (counts / n_respondents) * 100\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    counts.plot(kind=\"barh\", ax=ax)\n",
    "\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.set_xlabel(\"Participants selecting option\", alpha=0.6)\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.tick_params(axis='y', rotation=0)\n",
    "    ax.grid(axis='x', alpha=0.6)\n",
    "    ax.grid(axis='y', visible=False)\n",
    "    for spine in ['top','right','bottom']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "\n",
    "    for i, (cat, count) in enumerate(counts.items()):\n",
    "        pct = percent.loc[cat]\n",
    "        ax.text(count + max(counts)*0.01, i, f\"{pct:.0f}%\\n({count})\",\n",
    "                ha=\"left\", va=\"center\", alpha=0.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "df_preprocessed, n_respondents = preprocess_topics(df_with_second_conv[[\"Q9\"]], \"Q9\")\n",
    "\n",
    "plot_topics(df_preprocessed, n_respondents, \"Q9\", \"Conversation topic\")\n"
   ],
   "id": "7f854c7c8e2b6f05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Q10: Confidence",
   "id": "440ac422cb3d2639"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "q10 = df_with_second_conv[\"Q10_1\"].dropna()\n",
    "\n",
    "mapping = {\n",
    "    \"1 (Strongly disagree)\": \"1\",\n",
    "    \"2\": \"2\",\n",
    "    \"3\": \"3\",\n",
    "    \"4\": \"4\",\n",
    "    \"5 (Strongly agree)\": \"5\",\n",
    "    \"1\": \"1\",\n",
    "    \"5\": \"5\"\n",
    "}\n",
    "q10 = q10.replace(mapping)\n",
    "\n",
    "order = [\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "labels_long = [\"Strongly Disagree\",\"Disagree\",\"Neutral\",\"Agree\",\"Strongly Agree\"]\n",
    "\n",
    "counts = q10.value_counts().reindex(order, fill_value=0)\n",
    "props = (counts / counts.sum()).reindex(order)\n",
    "\n",
    "print(props)\n",
    "\n",
    "segments = np.array([ -props[\"1\"], -props[\"2\"], props[\"3\"], props[\"4\"], props[\"5\"] ], dtype=float)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13, 4))\n",
    "\n",
    "cmap = plt.colormaps.get_cmap(\"RdYlGn\")\n",
    "colors = [cmap(i/4) for i in range(5)]\n",
    "\n",
    "left = 0.0\n",
    "for seg, col in zip(segments, colors):\n",
    "    ax.barh(\n",
    "        [\"Q10\"],\n",
    "        [seg],\n",
    "        left=left,\n",
    "        color=col,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.2,\n",
    "        height=0.5\n",
    "    )\n",
    "    left += seg\n",
    "\n",
    "# Center line and light grid like the example\n",
    "ax.axvline(0, color=\"black\", linewidth=1, alpha=0.6)\n",
    "ax.grid(axis=\"x\", linewidth=0.5, alpha=0.6)\n",
    "ax.grid(axis=\"y\", visible=False)\n",
    "\n",
    "# Remove spines for a clean look\n",
    "for spine in [\"top\", \"right\", \"left\"]:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "\n",
    "# Title and x label\n",
    "ax.set_title(\"I felt confident talking about the topic.\", pad=16)\n",
    "\n",
    "# Format x-axis as percentages from -100% to +100%\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_xticks(np.linspace(-1, 1, 9))\n",
    "ax.set_xticklabels([f\"{int(abs(x)*100)}%\" for x in np.linspace(-1,1,9)])\n",
    "\n",
    "# y-axis label\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_yticks([\"Q10\"])\n",
    "\n",
    "centers = []\n",
    "left = 0.0\n",
    "for seg in segments:\n",
    "    centers.append(left + seg/2)\n",
    "    left += seg\n",
    "\n",
    "def text_color(rgba):\n",
    "    r,g,b,a = rgba\n",
    "    lum = 0.2126*r + 0.7152*g + 0.0722*b\n",
    "    return \"black\" if lum > 0.65 else \"white\"\n",
    "\n",
    "# Add labels only if segment is wide enough (>= 3%)\n",
    "for ctr, seg, lab, col, prop in zip(centers, segments, labels_long, colors, props):\n",
    "    width = abs(seg)\n",
    "    if width >= 0.03:\n",
    "        ax.text(\n",
    "            ctr,\n",
    "            0,\n",
    "            f\"{int(round(width*100))}%\",\n",
    "            va=\"center\",\n",
    "            ha=\"center\",\n",
    "            color=text_color(col),\n",
    "        )\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "handles = [Patch(facecolor=c, edgecolor=\"white\", label=l)\n",
    "           for c, l in zip(colors, labels_long)]\n",
    "\n",
    "ax.legend(\n",
    "    handles=handles,\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.5, -0.1),  # bottom center\n",
    "    ncol=5,\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "b62ed437a359eeba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Q11 & Q13: Emotions",
   "id": "73c71587c5367271"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def explode_emotions(dataframe, col):\n",
    "    ans = dataframe.loc[dataframe[col].notna(), [col]].copy()\n",
    "    ans[col] = ans[col].astype(str).str.split(\",\")\n",
    "    exploded = ans.explode(col)\n",
    "    exploded[col] = exploded[col].astype(str).str.strip()\n",
    "    exploded = exploded[exploded[col] != \"\"]\n",
    "    exploded[col] = exploded[col].replace({\n",
    "        \"Other (please describe)\": \"Other\",\n",
    "    })\n",
    "\n",
    "    exploded[col] = exploded[col].str.replace(r\"\\s*;\\s*\", \", \", regex=True)\n",
    "    return exploded\n",
    "\n",
    "q11_exp = explode_emotions(df_with_second_conv, \"Q11\")\n",
    "q13_exp = explode_emotions(df_with_second_conv, \"Q13\")\n",
    "\n",
    "q11_den = df[\"Q11\"].notna().sum()\n",
    "q13_den = df[\"Q13\"].notna().sum()\n",
    "\n",
    "q11_counts = q11_exp[\"Q11\"].value_counts()\n",
    "q13_counts = q13_exp[\"Q13\"].value_counts()\n",
    "\n",
    "all_cats = sorted(set(q11_counts.index).union(set(q13_counts.index)))\n",
    "\n",
    "q11_counts = q11_counts.reindex(all_cats, fill_value=0)\n",
    "q13_counts = q13_counts.reindex(all_cats, fill_value=0)\n",
    "\n",
    "order = pd.Series(q11_counts.values + q13_counts.values, index=all_cats).sort_values(ascending=True).index\n",
    "q11_counts = q11_counts.reindex(order)\n",
    "q13_counts = q13_counts.reindex(order)\n",
    "\n",
    "\n",
    "q11_pct = (q11_counts / q11_den * 100).round(1)\n",
    "q13_pct = (q13_counts / q13_den * 100).round(1)\n",
    "\n",
    "\n",
    "cats = q11_counts.index.tolist()\n",
    "\n",
    "x = np.arange(len(cats))\n",
    "width = 0.4\n",
    "\n",
    "colors = plt.cm.tab20.colors\n",
    "color_own = colors[0]\n",
    "color_other = colors[1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bars1 = ax.barh(x + width/2, q11_counts.values, height=width, label=\"Own emotions\", color=color_own)\n",
    "bars2 = ax.barh(x - width/2, q13_counts.values, height=width, label=\"Others' emotions\", color=color_other)\n",
    "\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(cats)\n",
    "ax.set_xlabel(\"Participants selecting option\", alpha=0.6)\n",
    "ax.set_title(\"Emotions during conversation\")\n",
    "ax.legend()\n",
    "\n",
    "ax.grid(axis='x', alpha=0.4)\n",
    "ax.grid(axis='y', visible=False)\n",
    "for spine in ['top','right','bottom']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "\n",
    "\n",
    "for bars, pct_series, count_series, offset in [\n",
    "    (bars1, q11_pct, q11_counts, -0.2),\n",
    "    (bars2, q13_pct, q13_counts, 0.2)\n",
    "]:\n",
    "    for i, bar in enumerate(bars):\n",
    "        count = count_series.iloc[i]\n",
    "        pct = pct_series.iloc[i]\n",
    "        if count > 0:\n",
    "            ax.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2,\n",
    "                    f\"{pct}%\", va=\"center\", ha=\"left\", fontsize=12, alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "e65b9f7413170fcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Q17: Did you have, or do you plan to have, a follow-up conversation?",
   "id": "49e154e0408671e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def preprocess_initiator(df_input, column):\n",
    "    df_input = df_input.copy()\n",
    "\n",
    "    df_exploded = df_input.dropna(subset=[column]).explode(column)\n",
    "\n",
    "    df_exploded[column] = df_exploded[column].replace({\n",
    "        \"Yes, I had (How many?)\": \"Yes, I had\",\n",
    "        \"Yes, I already had a follow-up conversation (How many?)\": \"Yes, I had\"\n",
    "    })\n",
    "\n",
    "    return df_exploded.reset_index()[[column]]\n",
    "\n",
    "def plot_initiator(df_input, column, title):\n",
    "    counts = df_input[column].value_counts()\n",
    "\n",
    "    counts = counts.sort_values(ascending=True)\n",
    "\n",
    "    colors = plt.cm.tab20.colors\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "    wedges, texts, autotexts = ax.pie(counts, labels=counts.index, autopct='%1.f%%', colors=colors)\n",
    "\n",
    "    for autotext, label in zip(autotexts, counts.index):\n",
    "        percentage_text = autotext.get_text()\n",
    "        count = counts[label]\n",
    "        autotext.set_text(f'{percentage_text}\\n({count})')\n",
    "\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "df_preprocessed = preprocess_initiator(df_with_second_conv[[\"Q17\"]], \"Q17\")\n",
    "\n",
    "plot_initiator(df_preprocessed, \"Q17\", 'Did you have a follow-up conversation?')\n"
   ],
   "id": "6a68714c0ac3ebc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Correlations",
   "id": "7c7e2b1ffb27c6c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Correlation between conversation factors and outcomes",
   "id": "e52814205d203799"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prepare numeric subset",
   "id": "ef73dc8845ad56c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cols_interest = [\"Q3\", \"Q6\", \"Q17\", \"Q15\"]\n",
    "subset = df_with_second_conv[cols_interest].dropna().copy()\n",
    "\n",
    "# Q3: number of people -> numeric, round to int, remove outliers >20\n",
    "subset[\"Q3_num\"] = pd.to_numeric(subset[\"Q3\"], errors=\"coerce\").round()\n",
    "subset[\"Q3_num\"] = subset[\"Q3_num\"].where(subset[\"Q3_num\"] <= 20)\n",
    "subset[\"Q3_num\"] = subset[\"Q3_num\"].astype(\"Int64\")\n",
    "\n",
    "# Q6: whether additional people joined (collapse known/stranger into 1)\n",
    "map_q6 = {\n",
    "    \"No\": 0,\n",
    "    \"Yes, somebody I know\": 1,\n",
    "    \"Yes, a stranger\": 1\n",
    "}\n",
    "subset[\"Q6_num\"] = subset[\"Q6\"].map(map_q6).astype(\"float\")\n",
    "\n",
    "# Q17: follow-ups (ordinal: No=0, Plan=1, Yes=2)\n",
    "map_q17 = {\n",
    "    \"No\": 0,\n",
    "    \"No, but I plan to have one in the future\": 1,\n",
    "    \"Yes, I had (How many?)\": 2\n",
    "}\n",
    "subset[\"Q17_num\"] = subset[\"Q17\"].map(map_q17).astype(\"float\")\n",
    "\n",
    "# Q15: behavioral change (binary)\n",
    "map_q15 = {\"No\": 0, \"Yes\": 1}\n",
    "subset[\"Q15_num\"] = subset[\"Q15\"].map(map_q15).astype(\"float\")\n",
    "\n",
    "numeric_subset = subset[[\"Q3_num\", \"Q6_num\", \"Q17_num\", \"Q15_num\"]].astype(\"float\")\n"
   ],
   "id": "44e8439c4a5ea8a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Spearman correlation",
   "id": "2fab2e83e70765b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "corr = numeric_subset.corr(method=\"spearman\")\n",
    "\n",
    "cols = numeric_subset.columns\n",
    "pvals = pd.DataFrame(np.ones((len(cols), len(cols))), index=cols, columns=cols)\n",
    "\n",
    "for i, c1 in enumerate(cols):\n",
    "    for j, c2 in enumerate(cols):\n",
    "        if i < j:\n",
    "            valid = numeric_subset[[c1, c2]].dropna()\n",
    "            if len(valid) > 1:\n",
    "                r, p = spearmanr(valid[c1], valid[c2])\n",
    "            else:\n",
    "                r, p = np.nan, np.nan\n",
    "            pvals.loc[c1, c2] = p\n",
    "            pvals.loc[c2, c1] = p\n",
    "\n",
    "rename_map = {\n",
    "    \"Q3_num\": \"Conversation size\",\n",
    "    \"Q6_num\": \"People joined\",\n",
    "    \"Q17_num\": \"Follow-ups\",\n",
    "    \"Q15_num\": \"Behavioral change\"\n",
    "}\n",
    "corr_renamed = corr.rename(index=rename_map, columns=rename_map)\n",
    "pvals_renamed = pvals.rename(index=rename_map, columns=rename_map)\n",
    "\n",
    "print(\"Spearman correlation matrix (rounded):\\n\")\n",
    "print(corr_renamed.round(3))\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(\n",
    "    corr_renamed, annot=True, fmt=\".2f\",\n",
    "    cmap=\"bwr\", vmin=-1, vmax=1, square=True,\n",
    "    cbar_kws={\"label\": \"Spearman r\"}\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "900d3a84b727a783",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Logistic regression",
   "id": "c0a2f586bb63a5df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "reg_data = numeric_subset.dropna(subset=[\"Q3_num\", \"Q6_num\", \"Q17_num\", \"Q15_num\"]).astype(float)\n",
    "\n",
    "X = reg_data[[\"Q3_num\", \"Q6_num\", \"Q17_num\"]]\n",
    "y = reg_data[\"Q15_num\"]\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "logit_model = sm.Logit(y, X).fit(disp=False)\n",
    "print(logit_model.summary())\n",
    "\n",
    "q3_range = np.arange(1, 16)\n",
    "avg_q6 = reg_data[\"Q6_num\"].mean()\n",
    "avg_q17 = reg_data[\"Q17_num\"].mean()\n",
    "\n",
    "X_pred = pd.DataFrame({\n",
    "    \"const\": 1.0,\n",
    "    \"Q3_num\": q3_range,\n",
    "    \"Q6_num\": avg_q6,\n",
    "    \"Q17_num\": avg_q17\n",
    "})\n",
    "pred_probs = logit_model.predict(X_pred)\n"
   ],
   "id": "ecffe757370ca4c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Correlation between emotions",
   "id": "e25fb1eb58b8cc98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "emotions = [\n",
    "    \"Interested/curious\",\n",
    "    \"Worried/anxious\",\n",
    "    \"Confident/informed\",\n",
    "    \"Annoyed\",\n",
    "    \"Helpful/responsible\",\n",
    "    \"Indifferent\",\n",
    "    \"Other (please describe)\"\n",
    "]\n",
    "\n",
    "def clean_and_encode(series, emotions):\n",
    "    cleaned = series.dropna().replace({\n",
    "        emotions[0]: emotions[0]\n",
    "    })\n",
    "\n",
    "    # Remove header-like rows\n",
    "    cleaned = cleaned[~cleaned.str.contains(\"How did you feel|How do you think\", na=False)]\n",
    "\n",
    "    # Split values by comma, strip spaces\n",
    "    split = cleaned.str.split(\",\").apply(lambda x: [s.strip() for s in x])\n",
    "\n",
    "    # Create one-hot encoding\n",
    "    encoded = pd.DataFrame(0, index=series.index, columns=emotions)\n",
    "    for idx, vals in split.items():\n",
    "        for v in vals:\n",
    "            if v in emotions:\n",
    "                encoded.at[idx, v] = 1\n",
    "            else:\n",
    "                encoded.at[idx, \"Other (please describe)\"] = 1\n",
    "\n",
    "    return encoded\n",
    "\n",
    "q11_encoded = clean_and_encode(df_with_second_conv[\"Q11\"].dropna(), emotions)\n",
    "q13_encoded = clean_and_encode(df_with_second_conv[\"Q13\"].dropna(), emotions)\n"
   ],
   "id": "f272d965e449d560",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cross-tabulation\n",
    "crosstab = q11_encoded.T.dot(q13_encoded)\n",
    "\n",
    "crosstab_percent = crosstab.div(crosstab.sum(axis=1), axis=0).fillna(0)\n",
    "\n",
    "alignment_scores = (q11_encoded & q13_encoded).sum(axis=1)\n",
    "misalignment_scores = (q11_encoded ^ q13_encoded).sum(axis=1)\n",
    "\n",
    "alignment_summary = {\n",
    "    \"Perfect alignment\": (misalignment_scores == 0).sum(),\n",
    "    \"Partial alignment\": ((alignment_scores > 0) & (misalignment_scores > 0)).sum(),\n",
    "    \"No alignment\": (alignment_scores == 0).sum()\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(crosstab_percent, annot=True, cmap=\"Blues\", fmt=\".2f\")\n",
    "plt.title(\"Cross-tabulation of Emotions (Row-normalized)\")\n",
    "plt.ylabel(\"self-assessment\")\n",
    "plt.xlabel(\"other's assessment\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "alignment_summary\n"
   ],
   "id": "33344ef98c4219a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "combined = pd.concat([q11_encoded.add_prefix(\"Q11_\"),\n",
    "                      q13_encoded.add_prefix(\"Q13_\")], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(combined)\n",
    "\n",
    "inertias = []\n",
    "for k in range(2, 6):\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    km.fit(X_scaled)\n",
    "    inertias.append((k, km.inertia_))\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=combined.columns)\n",
    "\n",
    "positive_cols = [\n",
    "    \"Q11_Interested/curious\",\"Q11_Confident/informed\",\"Q11_Helpful/responsible\",\n",
    "    \"Q13_Interested/curious\",\"Q13_Confident/informed\",\"Q13_Helpful/responsible\"\n",
    "]\n",
    "negative_cols = [\n",
    "    \"Q11_Worried/anxious\",\"Q11_Annoyed\",\n",
    "    \"Q13_Worried/anxious\",\"Q13_Annoyed\"\n",
    "]\n",
    "indifferent_cols = [\"Q11_Indifferent\",\"Q13_Indifferent\"]\n",
    "\n",
    "profiles = pd.DataFrame({\n",
    "    \"pos_score\": centroids[positive_cols].mean(axis=1),\n",
    "    \"neg_score\": centroids[negative_cols].mean(axis=1),\n",
    "    \"indiff_score\": centroids[indifferent_cols].mean(axis=1),\n",
    "})\n",
    "\n",
    "def name_cluster(row, pos_thr=0.15, neg_thr=0.15, indiff_thr=0.15):\n",
    "    pos_high = row[\"pos_score\"] > pos_thr\n",
    "    neg_high = row[\"neg_score\"] > neg_thr\n",
    "    indiff_high = row[\"indiff_score\"] > indiff_thr\n",
    "\n",
    "    if neg_high and not pos_high:\n",
    "        return \"Anxious/Annoyed\"\n",
    "    if pos_high and not neg_high:\n",
    "        return \"Confident/Helpful/Curious\"\n",
    "    if indiff_high and not pos_high and not neg_high:\n",
    "        return \"Neutral/Indifferent\"\n",
    "\n",
    "    if row[\"neg_score\"] == max(row[\"pos_score\"], row[\"neg_score\"], row[\"indiff_score\"]):\n",
    "        return \"Anxious/Annoyed\"\n",
    "    if row[\"pos_score\"] == max(row[\"pos_score\"], row[\"neg_score\"], row[\"indiff_score\"]):\n",
    "        return \"Confident/Helpful/Curious\"\n",
    "    return \"Neutral/Indifferent\"\n",
    "\n",
    "cluster_names = profiles.apply(name_cluster, axis=1)\n",
    "# Map numeric labels -> human-friendly names\n",
    "label_to_name = {i: cluster_names.iloc[i] for i in range(len(cluster_names))}\n",
    "named_labels = pd.Series(labels).map(label_to_name)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=named_labels, alpha=0.7)\n",
    "plt.title(\"Clustering of Conversations (PCA projection)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()\n",
    "\n",
    "cluster_profiles = centroids.T\n",
    "cluster_profiles.columns = [f\"{label_to_name[i]} (C{i})\" for i in range(len(cluster_names))]\n",
    "\n",
    "cluster_sizes_named = named_labels.value_counts().sort_values(ascending=False)\n",
    "cluster_distribution_named = (cluster_sizes_named / cluster_sizes_named.sum() * 100).round(2)\n",
    "\n",
    "cluster_summary_named = pd.DataFrame({\n",
    "    \"Count\": cluster_sizes_named,\n",
    "    \"Percentage\": cluster_distribution_named\n",
    "})\n",
    "\n",
    "print(\"Cluster name mapping (index -> name):\")\n",
    "print(label_to_name)\n",
    "print(\"\\nCluster sizes and distribution by name:\")\n",
    "print(cluster_summary_named)\n"
   ],
   "id": "e55daee877805c08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Correlation between confidence",
   "id": "d62a87bb6e3f4b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cols = [\"Q10_1\", \"Q15\", \"Q39_1\", \"Q35\", \"Q36\", \"Q37\"]\n",
    "df_subset = df_with_second_conv[cols].copy()\n",
    "\n",
    "# Function to extract numeric Likert values\n",
    "def extract_likert(val):\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    try:\n",
    "        return int(str(val).split()[0])  # take first number in string\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Process main variables\n",
    "df_subset[\"Q10_1_num\"] = df_subset[\"Q10_1\"].apply(extract_likert)\n",
    "df_subset[\"Q39_1_num\"] = df_subset[\"Q39_1\"].apply(extract_likert)\n",
    "df_subset[\"Q15_bin\"] = df_subset[\"Q15\"].str.strip().str.lower().map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "# Process demographics\n",
    "df_subset[\"Q35_age\"] = pd.to_numeric(df_subset[\"Q35\"], errors=\"coerce\")\n",
    "df_subset[\"Q36_gender\"] = df_subset[\"Q36\"].astype(\"category\")\n",
    "df_subset[\"Q37_country\"] = df_subset[\"Q37\"].astype(\"category\")\n",
    "\n",
    "# Drop missing values for key vars\n",
    "df_clean = df_subset.dropna(subset=[\"Q10_1_num\", \"Q15_bin\", \"Q39_1_num\", \"Q35_age\", \"Q36_gender\", \"Q37_country\"])\n",
    "\n",
    "# Correlation still only for numeric/ordinal vars\n",
    "corr = df_clean[[\"Q10_1_num\", \"Q15_bin\", \"Q39_1_num\", \"Q35_age\"]].corr(method=\"spearman\")\n",
    "\n",
    "# Rename for clarity\n",
    "corr_renamed = corr.rename(index={\n",
    "    \"Q10_1_num\": \"Confidence\",\n",
    "    \"Q15_bin\": \"Behavioral Change\",\n",
    "    \"Q39_1_num\": \"Willingness to give advice\",\n",
    "    \"Q35_age\": \"Age\"\n",
    "}, columns={\n",
    "    \"Q10_1_num\": \"Confidence\",\n",
    "    \"Q15_bin\": \"Behavioral Change\",\n",
    "    \"Q39_1_num\": \"Willingness to give advice\",\n",
    "    \"Q35_age\": \"Age\"\n",
    "})\n",
    "\n",
    "# Plot heatmap for numeric vars\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(corr_renamed, annot=True, cmap=\"bwr\", vmin=-1, vmax=1, fmt=\".2f\")\n",
    "plt.show()\n"
   ],
   "id": "cb12d23c736d52d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_likert(val):\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    s = str(val).strip()\n",
    "    tok = s.split()[0]\n",
    "    try:\n",
    "        return int(tok)\n",
    "    except Exception:\n",
    "        for ch in s:\n",
    "            if ch.isdigit():\n",
    "                return int(ch)\n",
    "        return np.nan\n",
    "\n",
    "def standardize_gender(x: str) -> str:\n",
    "    x = (x or \"\").strip().lower()\n",
    "    if not x or \"what is your gender\" in x:\n",
    "        return np.nan\n",
    "    if x in {\"male\", \"man\"}:\n",
    "        return \"Male\"\n",
    "    if x in {\"female\", \"woman\"}:\n",
    "        return \"Female\"\n",
    "    if \"non\" in x and \"binary\" in x:\n",
    "        return \"Non-binary\"\n",
    "    if \"prefer\" in x and \"not\" in x:\n",
    "        return \"Prefer not to say\"\n",
    "    return \"Other\"\n",
    "\n",
    "cols = [\"Q10_1\", \"Q15\", \"Q39_1\", \"Q35\", \"Q36\", \"Q37\"]\n",
    "df_reg = df[cols].copy()\n",
    "\n",
    "prompt_mask = (\n",
    "    df_reg[\"Q36\"].astype(str).str.contains(\"What is your gender?\", case=False, na=False)\n",
    "    | df_reg[\"Q37\"].astype(str).str.contains(\"What is your country\", case=False, na=False)\n",
    ")\n",
    "df_reg = df_reg[~prompt_mask]\n",
    "\n",
    "df_reg[\"confidence\"]  = df_reg[\"Q10_1\"].apply(extract_likert)\n",
    "df_reg[\"advice\"]      = df_reg[\"Q39_1\"].apply(extract_likert)\n",
    "df_reg[\"behavior\"]    = df_reg[\"Q15\"].astype(str).str.strip().str.lower().map({\"yes\":1, \"no\":0})\n",
    "df_reg[\"age\"]         = pd.to_numeric(df_reg[\"Q35\"], errors=\"coerce\")\n",
    "df_reg[\"gender_std\"]  = df_reg[\"Q36\"].astype(str).map(standardize_gender)\n",
    "df_reg[\"country_std\"] = df_reg[\"Q37\"].astype(str).str.strip()\n",
    "\n",
    "counts = df_reg[\"country_std\"].value_counts(dropna=True)\n",
    "keep_countries = counts[counts >= 5].index.tolist()\n",
    "df_reg[\"country_reduced\"] = np.where(df_reg[\"country_std\"].isin(keep_countries),\n",
    "                                     df_reg[\"country_std\"], \"Other\")\n",
    "\n",
    "X_core = df_reg[[\"advice\", \"behavior\", \"age\"]]\n",
    "\n",
    "X_gender  = pd.get_dummies(df_reg[\"gender_std\"],  prefix=\"gender\",  drop_first=True, dtype=float)\n",
    "X_country = pd.get_dummies(df_reg[\"country_reduced\"], prefix=\"country\", drop_first=True, dtype=float)\n",
    "\n",
    "X = pd.concat([X_core, X_gender, X_country], axis=1)\n",
    "\n",
    "y = df_reg[\"confidence\"]\n",
    "data = pd.concat([y, X], axis=1).dropna()\n",
    "\n",
    "y_clean = data[\"confidence\"].astype(int)\n",
    "X_clean = data.drop(columns=[\"confidence\"]).apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "keep_cols = [c for c in X_clean.columns if X_clean[c].nunique() > 1]\n",
    "X_clean = X_clean[keep_cols]\n",
    "\n",
    "X_clean = X_clean.astype(float)\n",
    "\n",
    "print(f\"N after dropping NaNs: {len(y_clean)}\")\n",
    "print(f\"Predictors used ({len(X_clean.columns)}): {list(X_clean.columns)}\")\n",
    "\n",
    "model = OrderedModel(y_clean, X_clean, distr='logit')\n",
    "res = model.fit(method='bfgs', disp=False)\n",
    "\n",
    "print(f\"\\nCountries kept (>=5 respondents): {sorted(set(df_reg.loc[data.index, 'country_reduced']))}\")\n",
    "print(res.summary())\n"
   ],
   "id": "e65263d1c1112034",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sankey",
   "id": "bc9ab77252c4f865"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "from itertools import product\n",
    "import plotly.graph_objects as go\n",
    "import plotly.colors as pc\n",
    "\n",
    "Q8_COL  = \"Q8\"\n",
    "Q9_COL  = \"Q9\"\n",
    "Q15_COL = \"Q15\"\n",
    "MULTI_SEP = \",\"\n",
    "\n",
    "def split_multi(val, sep=MULTI_SEP):\n",
    "    if pd.isna(val):\n",
    "        return []\n",
    "\n",
    "    parts = [p.strip(' \"\\'') for p in str(val).split(sep)]\n",
    "    parts = [re.sub(r'^\\s+|\\s+$', '', p) for p in parts]\n",
    "    return [p for p in parts if p and p.lower() != \"nan\"]\n",
    "\n",
    "def short_label(s, max_len=28):\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "\n",
    "    s2 = re.sub(r\"\\s*\\(.*?\\)\", \"\", str(s)).strip()\n",
    "    return (s2[:max_len-1] + \"…\") if len(s2) > max_len else s2\n",
    "\n",
    "def order_with_other_last(count_series):\n",
    "    if count_series is None or len(count_series) == 0:\n",
    "        return []\n",
    "\n",
    "    labels = list(count_series.index)\n",
    "    other_label = \"Other (please specify)\"\n",
    "    normal = [x for x in labels if other_label.lower() not in str(x).lower()]\n",
    "    other  = [x for x in labels if other_label.lower() in  str(x).lower()]\n",
    "    return normal + other\n",
    "\n",
    "def rgba(hex_or_rgb, alpha=0.55):\n",
    "    s = hex_or_rgb.strip()\n",
    "    if s.startswith(\"#\") and len(s) == 7:\n",
    "        r = int(s[1:3], 16); g = int(s[3:5], 16); b = int(s[5:7], 16)\n",
    "        return f\"rgba({r},{g},{b},{alpha})\"\n",
    "    if s.startswith(\"rgb(\"):\n",
    "        return s.replace(\"rgb(\", \"rgba(\").replace(\")\", f\",{alpha})\")\n",
    "    return s\n",
    "\n",
    "for col in [Q8_COL, Q9_COL, Q15_COL]:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Column '{col}' not found in CSV. Found: {list(df.columns)}\")\n",
    "\n",
    "df[\"_Q8_list\"]  = df[Q8_COL].apply(split_multi)\n",
    "df[\"_Q9_list\"]  = df[Q9_COL].apply(split_multi)\n",
    "df[\"_Q15_list\"] = df[Q15_COL].apply(split_multi)\n",
    "\n",
    "resp_Q8  = df[\"_Q8_list\"].explode().dropna().value_counts()   # respondents selecting each Q8\n",
    "resp_Q9  = df[\"_Q9_list\"].explode().dropna().value_counts()   # respondents selecting each Q9\n",
    "resp_Q15 = df[\"_Q15_list\"].explode().dropna().value_counts()  # works whether single or multi\n",
    "\n",
    "# Build edges via cartesian products per respondent\n",
    "rows_89 = []\n",
    "for _, r in df.iterrows():\n",
    "    if r[\"_Q8_list\"] and r[\"_Q9_list\"]:\n",
    "        for a, b in product(r[\"_Q8_list\"], r[\"_Q9_list\"]):\n",
    "            rows_89.append((a, b))\n",
    "edges_89 = (\n",
    "    pd.DataFrame(rows_89, columns=[\"Q8\", \"Q9\"]).value_counts().reset_index(name=\"count\")\n",
    "    if rows_89 else pd.DataFrame(columns=[\"Q8\",\"Q9\",\"count\"])\n",
    ")\n",
    "\n",
    "rows_915 = []\n",
    "for _, r in df.iterrows():\n",
    "    if r[\"_Q9_list\"] and r[\"_Q15_list\"]:\n",
    "        for a, b in product(r[\"_Q9_list\"], r[\"_Q15_list\"]):\n",
    "            rows_915.append((a, b))\n",
    "edges_915 = (\n",
    "    pd.DataFrame(rows_915, columns=[\"Q9\", \"Q15\"]).value_counts().reset_index(name=\"count\")\n",
    "    if rows_915 else pd.DataFrame(columns=[\"Q9\",\"Q15\",\"count\"])\n",
    ")\n",
    "\n",
    "# Order nodes (use respondent totals, then push 'Other' last)\n",
    "tot_Q8  = resp_Q8.sort_values(ascending=False)\n",
    "tot_Q9  = resp_Q9.sort_values(ascending=False)\n",
    "tot_Q15 = resp_Q15.sort_values(ascending=False)\n",
    "\n",
    "Q8_nodes  = order_with_other_last(tot_Q8)\n",
    "Q9_nodes  = order_with_other_last(tot_Q9)\n",
    "Q15_nodes = order_with_other_last(tot_Q15)\n",
    "\n",
    "# Labels & hover (prefix to avoid loops across columns)\n",
    "Q8_labels_short  = [f\"Q8: {short_label(x)}\"  for x in Q8_nodes]\n",
    "Q9_labels_short  = [f\"Q9: {short_label(x)}\"  for x in Q9_nodes]\n",
    "Q15_labels_short = [f\"Q15: {short_label(x)}\" for x in Q15_nodes]\n",
    "labels = Q8_labels_short + Q9_labels_short + Q15_labels_short\n",
    "\n",
    "Q8_hover  = [f\"Q8: {x}<br>Total respondents: {int(tot_Q8.get(x,0))}\"  for x in Q8_nodes]\n",
    "Q9_hover  = [f\"Q9: {x}<br>Total respondents: {int(tot_Q9.get(x,0))}\"  for x in Q9_nodes]\n",
    "Q15_hover = [f\"Q15: {x}<br>Total respondents: {int(tot_Q15.get(x,0))}\" for x in Q15_nodes]\n",
    "node_hover = Q8_hover + Q9_hover + Q15_hover\n",
    "\n",
    "# Index maps\n",
    "idx_Q8  = {x: i for i, x in enumerate(Q8_nodes)}\n",
    "offset_Q9  = len(Q8_nodes)\n",
    "offset_Q15 = len(Q8_nodes) + len(Q9_nodes)\n",
    "idx_Q9  = {x: offset_Q9  + i for i, x in enumerate(Q9_nodes)}\n",
    "idx_Q15 = {x: offset_Q15 + i for i, x in enumerate(Q15_nodes)}\n",
    "\n",
    "# Build links + hovers + colors\n",
    "src, tgt, val, link_hover, link_color = [], [], [], [], []\n",
    "\n",
    "PALETTE_Q8  = pc.qualitative.Pastel1\n",
    "PALETTE_Q9  = pc.qualitative.Pastel2\n",
    "PALETTE_Q15 = pc.qualitative.Set1\n",
    "\n",
    "Q8_colors  = {x: PALETTE_Q8[i % len(PALETTE_Q8)]  for i, x in enumerate(Q8_nodes)}\n",
    "Q9_colors  = {x: PALETTE_Q9[i % len(PALETTE_Q9)]  for i, x in enumerate(Q9_nodes)}\n",
    "Q15_colors = {x: PALETTE_Q15[i % len(PALETTE_Q15)] for i, x in enumerate(Q15_nodes)}\n",
    "\n",
    "if not edges_89.empty:\n",
    "    for _, r in edges_89.iterrows():\n",
    "        if r[\"Q8\"] not in idx_Q8 or r[\"Q9\"] not in idx_Q9:\n",
    "            continue\n",
    "        s = idx_Q8[r[\"Q8\"]]; t = idx_Q9[r[\"Q9\"]]; c = int(r[\"count\"])\n",
    "        src.append(s); tgt.append(t); val.append(c)\n",
    "        denom = tot_Q8.get(r[\"Q8\"], 0)\n",
    "        pct = (c / denom) * 100 if denom else 0\n",
    "        link_hover.append(\n",
    "            f\"Q8 → Q9<br>{r['Q8']} → {r['Q9']}<br>\"\n",
    "            f\"Count: {c} ({pct:.1f}% of respondents who selected this Q8)\"\n",
    "        )\n",
    "        link_color.append(rgba(Q8_colors[r[\"Q8\"]], 0.55))\n",
    "\n",
    "if not edges_915.empty:\n",
    "    for _, r in edges_915.iterrows():\n",
    "        if r[\"Q9\"] not in idx_Q9 or r[\"Q15\"] not in idx_Q15:\n",
    "            continue\n",
    "        s = idx_Q9[r[\"Q9\"]]; t = idx_Q15[r[\"Q15\"]]; c = int(r[\"count\"])\n",
    "        src.append(s); tgt.append(t); val.append(c)\n",
    "        denom = tot_Q9.get(r[\"Q9\"], 0)\n",
    "        pct = (c / denom) * 100 if denom else 0\n",
    "        link_hover.append(\n",
    "            f\"Q9 → Q15<br>{r['Q9']} → {r['Q15']}<br>\"\n",
    "            f\"Count: {c} ({pct:.1f}% of respondents who selected this Q9)\"\n",
    "        )\n",
    "        link_color.append(rgba(Q9_colors[r[\"Q9\"]], 0.55))\n",
    "\n",
    "# Plot\n",
    "fig_all = go.Figure(data=[go.Sankey(\n",
    "    arrangement=\"snap\",  # keep columns aligned\n",
    "    node=dict(\n",
    "        pad=18,\n",
    "        thickness=20,\n",
    "        line=dict(width=0.3, color=\"rgba(0,0,0,0.25)\"),\n",
    "        label=labels,\n",
    "        color=[Q8_colors[x] for x in Q8_nodes]\n",
    "            + [Q9_colors[x] for x in Q9_nodes]\n",
    "            + [Q15_colors[x] for x in Q15_nodes],\n",
    "        customdata=node_hover,\n",
    "        hovertemplate=\"%{customdata}<extra></extra>\",\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=src,\n",
    "        target=tgt,\n",
    "        value=val,\n",
    "        color=link_color,\n",
    "        customdata=link_hover,\n",
    "        hovertemplate=\"%{customdata}<extra></extra>\",\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig_all.update_layout(\n",
    "    title_text=\"Flow from Trigger (Q8) → Topic (Q9) → Outcome (Q15)\",\n",
    "    font=dict(size=13),\n",
    "    margin=dict(l=10, r=10, t=50, b=10),\n",
    ")\n",
    "\n",
    "fig_all.show()\n"
   ],
   "id": "fd41f3fedb080d50",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
